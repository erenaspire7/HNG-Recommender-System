{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System For Who to Follow on Lucid Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model\n",
    "\n",
    "The use of word2vec model which takes into account follower's history to be able to predict the next 6 people to follow by basis of how similar the users are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries needed \n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The details for connecting to the sql database of lucid blog which was hosted remotely\n",
    "mydb = mysql.connector.connect(host=\"remotemysql.com\",user=\"8SawWhnha4\", passwd=\"zFvOBIqbIz\",database=\"8SawWhnha4\")\n",
    "\n",
    "# The mysql engine to be queried and read \n",
    "engine = create_engine('mysql+mysqlconnector://8SawWhnha4:zFvOBIqbIz@remotemysql.com/8SawWhnha4')\n",
    "\n",
    "# Creating the dataframes from the user and following tables in the lucid blog database\n",
    "users = pd.read_sql_query(\"select * from users\", engine)\n",
    "following = pd.read_sql_query(\"select * from following\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Manipulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data, following is  (5296, 3)\n",
      "The column names are  Index(['my_id', 'follower_id', 'status'], dtype='object')\n",
      "The new dataframe head is     user_id  follower_id  status\n",
      "0        3            6       1\n",
      "1        6            3       1\n",
      "2        3            2       1\n",
      "3        3            7       1\n",
      "4        7            2       1\n"
     ]
    }
   ],
   "source": [
    "# Look  at the shape of the following data which will be used in predicting who to follow\n",
    "print(\"The shape of the data, following is \",following.shape)\n",
    "\n",
    "# See the first five rows\n",
    "following.head()\n",
    "\n",
    "# change the column names\n",
    "print(\"The column names are \",following.columns)\n",
    "\n",
    "# Rename the columns\n",
    "following.columns = ['user_id', 'follower_id', 'status']\n",
    "\n",
    "# Check a subset of the dataset to confirm if the columns have been renamed\n",
    "print(\"The new dataframe head is \",following.head())\n",
    "\n",
    "# Drop the status column\n",
    "following = following[['user_id', 'follower_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More manipulation of the dataset to prepare it for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users is  980  users\n"
     ]
    }
   ],
   "source": [
    "# Since we will be using Word2Vec, we need our follower id to be in string\n",
    "following['follower_id']= following['follower_id'].astype(str)\n",
    "\n",
    "# Create number of unique users\n",
    "unique_users = following['user_id'].unique().tolist()\n",
    "\n",
    "# check the length of uniques users\n",
    "print(\"The number of unique users is \",len(unique_users), \" users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the users and split into training and testing\n",
    "\n",
    "random.shuffle(unique_users)\n",
    "\n",
    "# Extract 100% of users\n",
    "unique_users = [unique_users[i] for i in range(round(1 * len(unique_users)))]\n",
    "\n",
    "# split into train and test data\n",
    "train_df = following[following['user_id'].isin(unique_users)]\n",
    "# test_df = following[~following['user_id'].isin(unique_users_train)]\n",
    "# print(train_df.shape)\n",
    "# print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 980/980 [00:00<00:00, 1023.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a follower history for each user\n",
    "\n",
    "# Follower History\n",
    "follower_history= []\n",
    "\n",
    "# Fill the list with follower id, this indicates the history of people following a user\n",
    "for i in tqdm(unique_users):\n",
    "    temp = train_df[train_df['user_id'] == i]['follower_id'].tolist()\n",
    "    follower_history.append(temp)\n",
    "    \n",
    "\n",
    "# # Testing data\n",
    "# follower_history_test = []\n",
    "# for i in tqdm(test_df['user_id'].unique()):\n",
    "#     temp = test_df[test_df['user_id'] == i]['follower_id'].tolist()\n",
    "#     follower_history_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of follower history for training data is  980\n"
     ]
    }
   ],
   "source": [
    "# View the lengths of the 2 histories\n",
    "print(\"The length of follower history for training data is \",len(follower_history))\n",
    "# print(\"The length of follower history for training data is \",len(follower_history_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chidibede\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33017, 52960)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the word2vec model to check the similar users\n",
    "# train word2vec model\n",
    "model = Word2Vec(window = 10, sg = 1, hs = 0,\n",
    "                 negative = 10, # for negative sampling\n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "model.build_vocab(follower_history, progress_per=200)\n",
    "\n",
    "model.train(follower_history, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the users table for easy recommendation\n",
    "users = users[[\"id\", \"name\", \"short_bio\"]]\n",
    "\n",
    "# remove duplicates\n",
    "users.drop_duplicates(inplace=True, subset='id', keep=\"last\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict who to follow\n",
    "def similar_users(vector, n = 6):\n",
    "    \n",
    "    # extract most similar users for the input vector\n",
    "    msu = model.wv.similar_by_vector(vector, topn= n+1)[1:]\n",
    "\n",
    "    # extract name of the similar users\n",
    "    similar_us = []\n",
    "    for i in msu:\n",
    "        similar_us.append(i[0])\n",
    "        people_to_follow = users[users['id'].isin(similar_us)]\n",
    "    return people_to_follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Word2Vec Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "The name of the test_user is  Alex Moses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chidibede\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People to Follow: \n",
      "       id                   name  \\\n",
      "2      3           Jeffrey Ogah   \n",
      "3      4  Oluwaseyi Oluwapelumi   \n",
      "114  115            Vivian Bena   \n",
      "119  120         folarin ayoola   \n",
      "159  160        Aderoju Olaitan   \n",
      "250  251    Bright Ogheneochuko   \n",
      "\n",
      "                                             short_bio  \n",
      "2    Front End Developer | React Developer | Mentor...  \n",
      "3    | Software Developer | DevOps Engineer | @linu...  \n",
      "114                                                     \n",
      "119  Technology-oriented, with passion for new chal...  \n",
      "159                              Mobile app developer.  \n",
      "250        Backend web developer and I.T Administrator  \n"
     ]
    }
   ],
   "source": [
    "# using a user from the test data, recommend who to fllow\n",
    "test_user = users['id'].astype(str)[6]\n",
    "print(test_user)\n",
    "# print the name of the user\n",
    "\n",
    "\n",
    "print(\"The name of the test_user is \",users.name[int(test_user)])\n",
    "\n",
    "# People to follow for the user\n",
    "try:\n",
    "    print(\"People to Follow: \\n\",similar_users(model[test_user]))\n",
    "except:\n",
    "    print(\"No recommendation for this user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Model\n",
    "\n",
    "The use of Tfidf model which takes into account the importance of each word in the bio description of each user and find the similarities using cosine similarities among different users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The users matrix shape is  (2293, 2242)\n"
     ]
    }
   ],
   "source": [
    "lucid_tfidf = TfidfVectorizer(stop_words='english')\n",
    "# filling the missing values with empty string\n",
    "users['short_bio'] = users['short_bio'].fillna('')\n",
    "# computing TF-IDF matrix required for calculating cosine similarity\n",
    "users_short_bio_matrix = lucid_tfidf.fit_transform(users['short_bio'])\n",
    "print(\"The users matrix shape is \", users_short_bio_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the cosine similarity for our users_short_bio_matrix \n",
    "cosine_similarity = linear_kernel(users_short_bio_matrix, users_short_bio_matrix)\n",
    "#getting our user indices\n",
    "user_indices = pd.Series(users['name'].index)\n",
    "\n",
    "#function to recommend user to follow based on similarities in their short_bio\n",
    "def recommend_to_follow(index, cosine_sim=cosine_similarity):\n",
    "    if index<users_short_bio_matrix.shape[0]:\n",
    "        id = user_indices[index]\n",
    "        # Get the pairwsie similarity scores of all names\n",
    "        # sorting them and getting top 5\n",
    "        similarity_scores = list(enumerate(cosine_sim[id]))\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        similarity_scores = similarity_scores[1:6]\n",
    "        \n",
    "        # Get the names index\n",
    "        lucid_index = [i[0] for i in similarity_scores]\n",
    "        # Return the top 5 most similar names\n",
    "        return users['name'].iloc[lucid_index]\n",
    "    else: return \"No recommedations for this user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the TFIDF Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People to follow  105     Damilare Olabimtan\n",
      "279        UDENKWOR NKECHI\n",
      "438         Angela Egerega\n",
      "604    chukwuemeka anyanwu\n",
      "641          Deborah Ajayi\n",
      "Name: name, dtype: object\n",
      "People to follow  480         Marylyn Idomo\n",
      "721     Ogunlaja Oreoluwa\n",
      "109        Ifeoluwa Aminu\n",
      "1684       Ndonna Ugwuede\n",
      "24          Abraham Ebuka\n",
      "Name: name, dtype: object\n",
      "People to follow  No recommedations for this user\n",
      "People to follow  1            Elijah Okokon\n",
      "2             Jeffrey Ogah\n",
      "3    Oluwaseyi Oluwapelumi\n",
      "4                     PoRH\n",
      "5             Seyi Onifade\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"People to follow \",recommend_to_follow(50))\n",
    "print(\"People to follow \",recommend_to_follow(245))\n",
    "print(\"People to follow \", recommend_to_follow(2456))\n",
    "print(\"People to follow \", recommend_to_follow(750))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who To Follow Recommendation on New Users Based on Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "notifications = pd.read_sql_query(\"select * from notifications\", engine)\n",
    "\n",
    "event_type_strength = {\n",
    "    'Like': 1.0,\n",
    "    'Replied':2.0,\n",
    "    'Commented': 3.0,\n",
    "    'Love': 4.0,\n",
    "    'Followed': 5.0\n",
    "}\n",
    "\n",
    "notifications['eventStrength'] = notifications['action'].apply(lambda x: event_type_strength[x])\n",
    "\n",
    "item_popularity_df = notifications.groupby('sender_id')['eventStrength'].sum().sort_values(ascending=False).reset_index()\n",
    "\n",
    "\n",
    "def who_to_follow():\n",
    "    return item_popularity_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the recommendation system for new users based on popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_id</th>\n",
       "      <th>eventStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2234</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1947</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sender_id  eventStrength\n",
       "0       2234          115.0\n",
       "1          3           46.0\n",
       "2          4           43.0\n",
       "3       1947           35.0\n",
       "4          1           26.0\n",
       "5          2           23.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_to_follow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
