{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System For Who to Follow on Lucid Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model\n",
    "\n",
    "The use of word2vec model which takes into account follower's history to be able to predict the next 6 people to follow by basis of how similar the users are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries needed \n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The details for connecting to the sql database of lucid blog which was hosted remotely\n",
    "mydb = mysql.connector.connect(host=\"remotemysql.com\",user=\"8SawWhnha4\", passwd=\"zFvOBIqbIz\",database=\"8SawWhnha4\")\n",
    "\n",
    "# The mysql engine to be queried and read \n",
    "engine = create_engine('mysql+mysqlconnector://8SawWhnha4:zFvOBIqbIz@remotemysql.com/8SawWhnha4')\n",
    "\n",
    "# Creating the dataframes from the user and following tables in the lucid blog database\n",
    "users = pd.read_sql_query(\"select * from users\", engine)\n",
    "following = pd.read_sql_query(\"select * from following\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Manipulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data, following is  (5296, 3)\n",
      "The column names are  Index(['my_id', 'follower_id', 'status'], dtype='object')\n",
      "The new dataframe head is     user_id  follower_id  status\n",
      "0        3            6       1\n",
      "1        6            3       1\n",
      "2        3            2       1\n",
      "3        3            7       1\n",
      "4        7            2       1\n"
     ]
    }
   ],
   "source": [
    "# Look  at the shape of the following data which will be used in predicting who to follow\n",
    "print(\"The shape of the data, following is \",following.shape)\n",
    "\n",
    "# See the first five rows\n",
    "following.head()\n",
    "\n",
    "# change the column names\n",
    "print(\"The column names are \",following.columns)\n",
    "\n",
    "# Rename the columns\n",
    "following.columns = ['user_id', 'follower_id', 'status']\n",
    "\n",
    "# Check a subset of the dataset to confirm if the columns have been renamed\n",
    "print(\"The new dataframe head is \",following.head())\n",
    "\n",
    "# Drop the status column\n",
    "following = following[['user_id', 'follower_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More manipulation of the dataset to prepare it for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users is  980  users\n"
     ]
    }
   ],
   "source": [
    "# Since we will be using Word2Vec, we need our follower id to be in string\n",
    "following['follower_id']= following['follower_id'].astype(str)\n",
    "\n",
    "# Create number of unique users\n",
    "unique_users = following['user_id'].unique().tolist()\n",
    "\n",
    "# check the length of uniques users\n",
    "print(\"The number of unique users is \",len(unique_users), \" users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the users and split into training and testing\n",
    "\n",
    "random.shuffle(unique_users)\n",
    "\n",
    "# Extract 100% of users\n",
    "unique_users = [unique_users[i] for i in range(round(1 * len(unique_users)))]\n",
    "\n",
    "# split into train and test data\n",
    "train_df = following[following['user_id'].isin(unique_users)]\n",
    "# test_df = following[~following['user_id'].isin(unique_users_train)]\n",
    "# print(train_df.shape)\n",
    "# print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 980/980 [00:00<00:00, 1098.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a follower history for each user\n",
    "\n",
    "# Follower History\n",
    "follower_history= []\n",
    "\n",
    "# Fill the list with follower id, this indicates the history of people following a user\n",
    "for i in tqdm(unique_users):\n",
    "    temp = train_df[train_df['user_id'] == i]['follower_id'].tolist()\n",
    "    follower_history.append(temp)\n",
    "    \n",
    "\n",
    "# # Testing data\n",
    "# follower_history_test = []\n",
    "# for i in tqdm(test_df['user_id'].unique()):\n",
    "#     temp = test_df[test_df['user_id'] == i]['follower_id'].tolist()\n",
    "#     follower_history_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of follower history for training data is  980\n"
     ]
    }
   ],
   "source": [
    "# View the lengths of the 2 histories\n",
    "print(\"The length of follower history for training data is \",len(follower_history))\n",
    "# print(\"The length of follower history for training data is \",len(follower_history_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chidibede\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32972, 52960)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the word2vec model to check the similar users\n",
    "# train word2vec model\n",
    "model = Word2Vec(window = 10, sg = 1, hs = 0,\n",
    "                 negative = 10, # for negative sampling\n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "model.build_vocab(follower_history, progress_per=200)\n",
    "\n",
    "model.train(follower_history, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the users table for easy recommendation\n",
    "users = users[[\"id\", \"name\", \"short_bio\"]]\n",
    "\n",
    "# remove duplicates\n",
    "users.drop_duplicates(inplace=True, subset='id', keep=\"last\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict who to follow\n",
    "def similar_users(vector, n = 6):\n",
    "    \n",
    "    # extract most similar users for the input vector\n",
    "    msu = model.wv.similar_by_vector(vector, topn= n+1)[1:]\n",
    "\n",
    "    # extract name of the similar users\n",
    "    similar_us = []\n",
    "    for i in msu:\n",
    "        similar_us.append(i[0])\n",
    "        people_to_follow = users[users['id'].isin(similar_us)]\n",
    "    return people_to_follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Model\n",
    "\n",
    "The use of Tfidf model which takes into account the importance of each word in the bio description of each user and find the similarities using cosine similarities among different users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The users matrix shape is  (2293, 2242)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "lucid_tfidf = TfidfVectorizer(stop_words='english')\n",
    "# filling the missing values with empty string\n",
    "users['short_bio'] = users['short_bio'].fillna('')\n",
    "# computing TF-IDF matrix required for calculating cosine similarity\n",
    "users_short_bio_matrix = lucid_tfidf.fit_transform(users['short_bio'])\n",
    "print(\"The users matrix shape is \", users_short_bio_matrix.shape)\n",
    "\n",
    "#calculating the cosine similarity for our users_short_bio_matrix \n",
    "cosine_similarity = linear_kernel(users_short_bio_matrix, users_short_bio_matrix)\n",
    "#getting our user indices\n",
    "user_indices = pd.Series(users['name'].index)\n",
    "\n",
    "#function to recommend user to follow based on similarities in their short_bio\n",
    "def recommend_to_follow(index, cosine_sim=cosine_similarity):\n",
    "    if index<users_short_bio_matrix.shape[0]:\n",
    "        id = user_indices[index]\n",
    "        # Get the pairwsie similarity scores of all names\n",
    "        # sorting them and getting top 5\n",
    "        similarity_scores = list(enumerate(cosine_sim[id]))\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        similarity_scores = similarity_scores[1:6]\n",
    "        \n",
    "        # Get the names index\n",
    "        lucid_index = [i[0] for i in similarity_scores]\n",
    "        # Return the top 5 most similar names\n",
    "        return users['name'].iloc[lucid_index]\n",
    "    else: return \"No recommedations for this user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Model\n",
    "\n",
    "The use of Tfidf model which takes into account the importance of each word in the bio description of each user and find the similarities using cosine similarities among different users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The users matrix shape is  (2293, 2242)\n"
     ]
    }
   ],
   "source": [
    "lucid_tfidf = TfidfVectorizer(stop_words='english')\n",
    "# filling the missing values with empty string\n",
    "users['short_bio'] = users['short_bio'].fillna('')\n",
    "# computing TF-IDF matrix required for calculating cosine similarity\n",
    "users_short_bio_matrix = lucid_tfidf.fit_transform(users['short_bio'])\n",
    "print(\"The users matrix shape is \", users_short_bio_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the cosine similarity for our users_short_bio_matrix \n",
    "cosine_similarity = linear_kernel(users_short_bio_matrix, users_short_bio_matrix)\n",
    "#getting our user indices\n",
    "user_indices = pd.Series(users['name'].index)\n",
    "\n",
    "#function to recommend user to follow based on similarities in their short_bio\n",
    "def recommend_to_follow(index, cosine_sim=cosine_similarity):\n",
    "    if index<users_short_bio_matrix.shape[0]:\n",
    "        id = user_indices[index]\n",
    "        # Get the pairwsie similarity scores of all names\n",
    "        # sorting them and getting top 5\n",
    "        similarity_scores = list(enumerate(cosine_sim[id]))\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        similarity_scores = similarity_scores[1:6]\n",
    "        \n",
    "        # Get the names index\n",
    "        lucid_index = [i[0] for i in similarity_scores]\n",
    "        # Return the top 5 most similar names\n",
    "        return users['name'].iloc[lucid_index]\n",
    "    else: return \"No recommedations for this user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the TFIDF Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People to follow  105     Damilare Olabimtan\n",
      "279        UDENKWOR NKECHI\n",
      "438         Angela Egerega\n",
      "604    chukwuemeka anyanwu\n",
      "641          Deborah Ajayi\n",
      "Name: name, dtype: object\n",
      "People to follow  480         Marylyn Idomo\n",
      "721     Ogunlaja Oreoluwa\n",
      "109        Ifeoluwa Aminu\n",
      "1684       Ndonna Ugwuede\n",
      "24          Abraham Ebuka\n",
      "Name: name, dtype: object\n",
      "People to follow  No recommedations for this user\n",
      "People to follow  1            Elijah Okokon\n",
      "2             Jeffrey Ogah\n",
      "3    Oluwaseyi Oluwapelumi\n",
      "4                     PoRH\n",
      "5             Seyi Onifade\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"People to follow \",recommend_to_follow(50))\n",
    "print(\"People to follow \",recommend_to_follow(245))\n",
    "print(\"People to follow \", recommend_to_follow(2456))\n",
    "print(\"People to follow \", recommend_to_follow(750))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who To Follow Recommendation on New Users Based on Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv(\"users_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the models\n",
    "# import pickle\n",
    "# with open(\"word2vec_who_to_follow_model.pkl\", 'wb') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
