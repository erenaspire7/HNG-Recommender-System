{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System For Who to Follow on Lucid Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model\n",
    "\n",
    "The use of word2vec model which takes into account follower's history to be able to predict the next 6 people to follow by basis of how similar the users are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries needed \n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The details for connecting to the sql database of lucid blog which was hosted remotely\n",
    "mydb = mysql.connector.connect(host=\"remotemysql.com\",user=\"8SawWhnha4\", passwd=\"zFvOBIqbIz\",database=\"8SawWhnha4\")\n",
    "\n",
    "# The mysql engine to be queried and read \n",
    "engine = create_engine('mysql+mysqlconnector://8SawWhnha4:zFvOBIqbIz@remotemysql.com/8SawWhnha4')\n",
    "\n",
    "# Creating the dataframes from the user and following tables in the lucid blog database\n",
    "users = pd.read_sql_query(\"select * from users\", engine)\n",
    "following = pd.read_sql_query(\"select * from following\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Manipulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data, following is  (5296, 3)\n",
      "The column names are  Index(['my_id', 'follower_id', 'status'], dtype='object')\n",
      "The new dataframe head is     user_id  follower_id  status\n",
      "0        3            6       1\n",
      "1        6            3       1\n",
      "2        3            2       1\n",
      "3        3            7       1\n",
      "4        7            2       1\n"
     ]
    }
   ],
   "source": [
    "# Look  at the shape of the following data which will be used in predicting who to follow\n",
    "print(\"The shape of the data, following is \",following.shape)\n",
    "\n",
    "# See the first five rows\n",
    "following.head()\n",
    "\n",
    "# change the column names\n",
    "print(\"The column names are \",following.columns)\n",
    "\n",
    "# Rename the columns\n",
    "following.columns = ['user_id', 'follower_id', 'status']\n",
    "\n",
    "# Check a subset of the dataset to confirm if the columns have been renamed\n",
    "print(\"The new dataframe head is \",following.head())\n",
    "\n",
    "# Drop the status column\n",
    "following = following[['user_id', 'follower_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More manipulation of the dataset to prepare it for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users is  980  users\n"
     ]
    }
   ],
   "source": [
    "# Since we will be using Word2Vec, we need our follower id to be in string\n",
    "following['follower_id']= following['follower_id'].astype(str)\n",
    "\n",
    "# Create number of unique users\n",
    "unique_users = following['user_id'].unique().tolist()\n",
    "\n",
    "# check the length of uniques users\n",
    "print(\"The number of unique users is \",len(unique_users), \" users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4994, 2)\n",
      "(302, 2)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the users and split into training and testing\n",
    "\n",
    "random.shuffle(unique_users)\n",
    "\n",
    "# Extract 95% of users\n",
    "unique_users_train = [unique_users[i] for i in range(round(0.95 * len(unique_users)))]\n",
    "\n",
    "# split into train and test data\n",
    "train_df = following[following['user_id'].isin(unique_users_train)]\n",
    "test_df = following[~following['user_id'].isin(unique_users_train)]\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 931/931 [00:01<00:00, 926.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 721.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a follower history for each user  for both training and testing data\n",
    "\n",
    "# Training data History\n",
    "follower_history_train = []\n",
    "\n",
    "# Fill the list with follower id, this indicates the history of people following a user\n",
    "for i in tqdm(unique_users_train):\n",
    "    temp = train_df[train_df['user_id'] == i]['follower_id'].tolist()\n",
    "    follower_history_train.append(temp)\n",
    "    \n",
    "\n",
    "# Testing data\n",
    "follower_history_test = []\n",
    "for i in tqdm(test_df['user_id'].unique()):\n",
    "    temp = test_df[test_df['user_id'] == i]['follower_id'].tolist()\n",
    "    follower_history_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of follower history for training data is  931\n",
      "The length of follower history for training data is  49\n"
     ]
    }
   ],
   "source": [
    "# View the lengths of the 2 histories\n",
    "print(\"The length of follower history for training data is \",len(follower_history_train))\n",
    "print(\"The length of follower history for training data is \",len(follower_history_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chidibede\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30072, 49940)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the word2vec model to check the similar users\n",
    "# train word2vec model\n",
    "model = Word2Vec(window = 10, sg = 1, hs = 0,\n",
    "                 negative = 10, # for negative sampling\n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "model.build_vocab(follower_history_train, progress_per=200)\n",
    "\n",
    "model.train(follower_history_train, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the users table for easy recommendation\n",
    "users = users[[\"id\", \"name\", \"short_bio\"]]\n",
    "\n",
    "# remove duplicates\n",
    "users.drop_duplicates(inplace=True, subset='id', keep=\"last\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict who to follow\n",
    "def similar_users(vector, n = 6):\n",
    "    \n",
    "    # extract most similar users for the input vector\n",
    "    msu = model.wv.similar_by_vector(vector, topn= n+1)[1:]\n",
    "\n",
    "    # extract name of the similar users\n",
    "    similar_us = []\n",
    "    for i in msu:\n",
    "        similar_us.append(i[0])\n",
    "        people_to_follow = users[users['id'].isin(similar_us)]\n",
    "    return people_to_follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Word2Vec Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the recommender system with the test data\n",
    "test_df = test_df.reset_index().drop('index',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "The name of the test_user is  PoRH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chidibede\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>short_bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jeffrey Ogah</td>\n",
       "      <td>Front End Developer | React Developer | Mentor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>folarin ayoola</td>\n",
       "      <td>Technology-oriented, with passion for new chal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>Aderoju Olaitan</td>\n",
       "      <td>Mobile app developer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>161</td>\n",
       "      <td>Frederick Damasus</td>\n",
       "      <td>Brand Identity and UX Designer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>Utibeka theresa nde</td>\n",
       "      <td>it's still me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>717</td>\n",
       "      <td>Adekoyejo Adeola</td>\n",
       "      <td>A front end developer and a tech enthusiast..p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                 name  \\\n",
       "2      3         Jeffrey Ogah   \n",
       "119  120       folarin ayoola   \n",
       "159  160      Aderoju Olaitan   \n",
       "160  161    Frederick Damasus   \n",
       "208  209  Utibeka theresa nde   \n",
       "716  717     Adekoyejo Adeola   \n",
       "\n",
       "                                             short_bio  \n",
       "2    Front End Developer | React Developer | Mentor...  \n",
       "119  Technology-oriented, with passion for new chal...  \n",
       "159                              Mobile app developer.  \n",
       "160                     Brand Identity and UX Designer  \n",
       "208                                     it's still me.  \n",
       "716  A front end developer and a tech enthusiast..p...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using a user from the test data, recommend who to fllow\n",
    "test_user = users['id'].astype(str)[3]\n",
    "print(test_user)\n",
    "# print the name of the user\n",
    "\n",
    "\n",
    "print(\"The name of the test_user is \",users.name[int(test_user)])\n",
    "\n",
    "# People to follow for the user\n",
    "similar_users(model[test_user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Model\n",
    "\n",
    "The use of Tfidf model which takes into account the importance of each word in the bio description of each user and find the similarities using cosine similarities among different users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucid_tfidf = TfidfVectorizer(stop_words='english')\n",
    "# filling the missing values with empty string\n",
    "users['short_bio'] = users['short_bio'].fillna('')\n",
    "# computing TF-IDF matrix required for calculating cosine similarity\n",
    "users_short_bio_matrix = lucid_tfidf.fit_transform(users['short_bio'])\n",
    "print(\"The users matrix shape is \", users_short_bio_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the cosine similarity for our users_short_bio_matrix \n",
    "cosine_similarity = linear_kernel(users_short_bio_matrix, users_short_bio_matrix)\n",
    "#getting our user indices\n",
    "user_indices = pd.Series(users['name'].index)\n",
    "\n",
    "#function to recommend user to follow based on similarities in their short_bio\n",
    "def recommend_to_follow(index, cosine_sim=cosine_similarity):\n",
    "    if index<users_short_bio_matrix.shape[0]:\n",
    "        id = user_indices[index]\n",
    "        # Get the pairwsie similarity scores of all names\n",
    "        # sorting them and getting top 5\n",
    "        similarity_scores = list(enumerate(cosine_sim[id]))\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        similarity_scores = similarity_scores[1:6]\n",
    "        \n",
    "        # Get the names index\n",
    "        lucid_index = [i[0] for i in similarity_scores]\n",
    "        # Return the top 5 most similar names\n",
    "        return users['name'].iloc[lucid_index]\n",
    "    else: return \"No recommedations for this user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the TFIDF Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"People to follow \",recommend_to_follow(50))\n",
    "print(\"People to follow \",recommend_to_follow(245))\n",
    "print(\"People to follow \", recommend_to_follow(2456))\n",
    "print(\"People to follow \", recommend_to_follow(750))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who To Follow Recommendation on New Users Based on Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notifications = pd.read_sql_query(\"select * from notifications\", engine)\n",
    "\n",
    "event_type_strength = {\n",
    "    'Like': 1.0,\n",
    "    'Replied':2.0,\n",
    "    'Commented': 3.0,\n",
    "    'Love': 4.0,\n",
    "    'Followed': 5.0\n",
    "}\n",
    "\n",
    "notifications['eventStrength'] = notifications['action'].apply(lambda x: event_type_strength[x])\n",
    "\n",
    "item_popularity_df = notifications.groupby('sender_id')['eventStrength'].sum().sort_values(ascending=False).reset_index()\n",
    "\n",
    "\n",
    "def who_to_follow():\n",
    "    return item_popularity_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the recommendation system for new users based on popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who_to_follow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
